{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-11T17:31:57.454180Z",
     "start_time": "2025-06-11T17:31:36.594879Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640) # pixeles ancho\n",
    "cap.set(4,480) # Alto\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    cv2.imshow(\"Camara\", img)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-11T18:59:51.944488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640) # pixeles ancho\n",
    "cap.set(4,480) # Alto\n",
    "\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,255), 3)\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confianza: \", confidence)\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Nombre de la clase: \", classNames[cls])\n",
    "            org = [x1,y1]\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            fontScale = 1\n",
    "            color = (255,0,0)\n",
    "            thickness = 2\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    cv2.imshow(\"Camara\", img)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "c2355a5458e9e03a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 114.0ms\n",
      "Confianza:  0.83\n",
      "Nombre de la clase:  person\n",
      "Speed: 5.2ms preprocess, 114.0ms inference, 9.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.3ms\n",
      "Confianza:  0.88\n",
      "Nombre de la clase:  person\n",
      "Speed: 2.8ms preprocess, 93.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 52.5ms\n",
      "Confianza:  0.89\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.7ms preprocess, 52.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 49.5ms\n",
      "Confianza:  0.88\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.5ms preprocess, 49.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 45.7ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.1ms preprocess, 45.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 50.0ms\n",
      "Confianza:  0.89\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.7ms preprocess, 50.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 45.5ms\n",
      "Confianza:  0.89\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.5ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.4ms\n",
      "Confianza:  0.88\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.2ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 47.4ms\n",
      "Confianza:  0.85\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.8ms preprocess, 47.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 45.7ms\n",
      "Confianza:  0.86\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.5ms preprocess, 45.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 46.2ms\n",
      "Confianza:  0.86\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Confianza:  0.86\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 43.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 47.3ms\n",
      "Confianza:  0.89\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 47.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 44.4ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.3ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 41.0ms\n",
      "Confianza:  0.88\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 41.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 45.3ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.5ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.5ms\n",
      "Confianza:  0.89\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.3ms preprocess, 43.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 48.1ms\n",
      "Confianza:  0.89\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.5ms preprocess, 48.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 45.1ms\n",
      "Confianza:  0.92\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.2ms preprocess, 45.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.6ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 42.8ms\n",
      "Confianza:  0.92\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.3ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 42.5ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.2ms preprocess, 42.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 38.6ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.3ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.6ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 40.9ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 40.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.4ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.8ms preprocess, 43.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 42.4ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.1ms preprocess, 42.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 46.7ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.5ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 41.9ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.3ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 42.9ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 41.7ms\n",
      "Confianza:  0.89\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.3ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 44.3ms\n",
      "Confianza:  0.92\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 44.9ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.6ms preprocess, 44.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 44.5ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.2ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 40.8ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.3ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 39.4ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.1ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 36.7ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.1ms preprocess, 36.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 37.0ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.2ms preprocess, 37.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 43.9ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.4ms preprocess, 43.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 45.9ms\n",
      "Confianza:  0.92\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.2ms preprocess, 45.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 42.3ms\n",
      "Confianza:  0.9\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.3ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 39.9ms\n",
      "Confianza:  0.91\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 40.5ms\n",
      "Confianza:  0.92\n",
      "Nombre de la clase:  person\n",
      "Speed: 1.1ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7503411b718e1d41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c53629e89099f494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21819d369686c930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32d3d558903f86b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
