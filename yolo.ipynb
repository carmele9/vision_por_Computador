{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-11T18:13:32.011207Z",
     "start_time": "2025-06-11T18:13:12.304550Z"
    }
   },
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import xml.etree.ElementTree as ET\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:17:42.223586Z",
     "start_time": "2025-06-11T18:17:42.220088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xml_dir = \"annotation/lego4/\"\n",
    "img_dir = \"images/lego4/\"\n",
    "labels = [\"lego\"]\n",
    "size = 416\n",
    "best_weight = \"full_yolo_backend.h5\"\n"
   ],
   "id": "2405729fe6e24b92",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:38:05.574168Z",
     "start_time": "2025-06-11T18:38:05.560153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_annotations(an_dir, img_dir, labels = []):\n",
    "    all_imgs = []\n",
    "    seen_labels = {}\n",
    "    for an in [x for x in sorted(os.listdir(an_dir)) if x.endswith(\".xml\")]:\n",
    "        img = {\"object\": []}\n",
    "        tree = ET.parse(an_dir + an)\n",
    "        for elem in tree.iter():\n",
    "            if \"filename\" in elem.tag:\n",
    "                img[\"filename\"] = img_dir + elem.text\n",
    "            if \"width\" in elem.tag:\n",
    "                img[\"width\"] = int(elem.text)\n",
    "            if \"height\" in elem.tag:\n",
    "                img[\"height\"] = int(elem.text)\n",
    "            if \"object\" in elem.tag or \"part\" in elem.tag:\n",
    "                obj = {}\n",
    "                for attr in list(elem):\n",
    "                    if \"name\" in attr.tag:\n",
    "                        obj[\"name\"] = attr.text\n",
    "                        if obj[\"name\"] in seen_labels:\n",
    "                            seen_labels[obj[\"name\"]] += 1\n",
    "                        else:\n",
    "                            seen_labels[obj[\"name\"]] = 1\n",
    "                        if len(labels) > 0 and obj[\"name\"] not in labels:\n",
    "                            break\n",
    "                        else:\n",
    "                            img[\"object\"] += [obj]\n",
    "                    if \"bndbox\" in attr.tag:\n",
    "                        for dim in list(attr):\n",
    "                            if \"xmin\" in dim.tag:\n",
    "                                obj[\"xmin\"] = int(round(float(dim.text)))\n",
    "                            if \"ymin\" in dim.tag:\n",
    "                                obj[\"ymin\"] = int(round(float(dim.text)))\n",
    "                            if \"xmax\" in dim.tag:\n",
    "                                obj[\"xmax\"] = int(round(float(dim.text)))\n",
    "                            if \"ymax\" in dim.tag:\n",
    "                                obj[\"ymax\"] = int(round(float(dim.text)))\n",
    "        if len(img[\"object\"]) > 0:\n",
    "            all_imgs += [img]\n",
    "    return all_imgs, seen_labels"
   ],
   "id": "2e1d1c366d5525e4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:39:49.295805Z",
     "start_time": "2025-06-11T18:39:49.160957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_imgs, train_labels = read_annotations(xml_dir, img_dir, labels)\n",
    "print(\"Imagenes: \", len(train_imgs), \"Labels: \", len(train_labels))"
   ],
   "id": "7301f30068e5cba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes:  323 Labels:  1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:44:08.430090Z",
     "start_time": "2025-06-11T18:44:08.423068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_val_split = int(0.8 * len(train_imgs))\n",
    "np.random.shuffle(train_imgs)\n",
    "vali_imgs = train_imgs[train_val_split:]\n",
    "train_imgs = train_imgs[:train_val_split]\n",
    "print(\"train: \", len(train_imgs), \"val: \", len(vali_imgs))"
   ],
   "id": "d696a0b4e61978a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  258 val:  65\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:53:24.670172Z",
     "start_time": "2025-06-11T18:53:24.568261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "\n",
    "    return float(intersect) / union\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "        self.c     = c\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score\n",
    "\n",
    "\n",
    "class BatchGenerator(Sequence):\n",
    "    def __init__(self, images,\n",
    "                       config,\n",
    "                       shuffle=True,\n",
    "                       jitter=True,\n",
    "                       norm=None):\n",
    "        self.generator = None\n",
    "\n",
    "        self.images = images\n",
    "        self.config = config\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "        self.jitter  = jitter\n",
    "        self.norm    = norm\n",
    "\n",
    "        self.anchors = [BoundBox(0, 0, config['ANCHORS'][2*i], config['ANCHORS'][2*i+1]) for i in range(int(len(config['ANCHORS'])//2))]\n",
    "\n",
    "        ### augmentors by https://github.com/aleju/imgaug\n",
    "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "        self.aug_pipe = iaa.Sequential(\n",
    "            [\n",
    "                sometimes(iaa.Affine()),\n",
    "                iaa.SomeOf((0, 5),\n",
    "                    [\n",
    "                        iaa.OneOf([\n",
    "                            iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                            iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                            iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                        ]),\n",
    "                        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                        iaa.OneOf([\n",
    "                            iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                        ]),\n",
    "                        iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                        iaa.Multiply((0.5, 1.5), per_channel=0.5), # change brightness of images (50-150% of original value)\n",
    "                        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                    ],\n",
    "                    random_order=True\n",
    "                )\n",
    "            ],\n",
    "            random_order=True\n",
    "        )\n",
    "\n",
    "        if shuffle: np.random.shuffle(self.images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(self.config['LABELS'])\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def load_annotation(self, i):\n",
    "        annots = []\n",
    "\n",
    "        for obj in self.images[i]['object']:\n",
    "            annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.config['LABELS'].index(obj['name'])]\n",
    "            annots += [annot]\n",
    "\n",
    "        if len(annots) == 0: annots = [[]]\n",
    "\n",
    "        return np.array(annots)\n",
    "\n",
    "    def load_image(self, i):\n",
    "        return cv2.imread(self.images[i]['filename'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        l_bound = idx*self.config['BATCH_SIZE']\n",
    "        r_bound = (idx+1)*self.config['BATCH_SIZE']\n",
    "\n",
    "        if r_bound > len(self.images):\n",
    "            r_bound = len(self.images)\n",
    "            l_bound = r_bound - self.config['BATCH_SIZE']\n",
    "\n",
    "        instance_count = 0\n",
    "\n",
    "        x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'], 3))                         # input images\n",
    "        b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))   # list of self.config['TRUE_self.config['BOX']_BUFFER'] GT boxes\n",
    "        y_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'],  self.config['GRID_W'], self.config['BOX'], 4+1+len(self.config['LABELS'])))                # desired network output\n",
    "\n",
    "        for train_instance in self.images[l_bound:r_bound]:\n",
    "            # augment input image and fix object's position and size\n",
    "            img, all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
    "\n",
    "            # construct output from object's x, y, w, h\n",
    "            true_box_index = 0\n",
    "\n",
    "            for obj in all_objs:\n",
    "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\n",
    "                    center_x = .5*(obj['xmin'] + obj['xmax'])\n",
    "                    center_x = center_x / (float(self.config['IMAGE_W']) / self.config['GRID_W'])\n",
    "                    center_y = .5*(obj['ymin'] + obj['ymax'])\n",
    "                    center_y = center_y / (float(self.config['IMAGE_H']) / self.config['GRID_H'])\n",
    "\n",
    "                    grid_x = int(np.floor(center_x))\n",
    "                    grid_y = int(np.floor(center_y))\n",
    "\n",
    "                    if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\n",
    "                        obj_indx  = self.config['LABELS'].index(obj['name'])\n",
    "\n",
    "                        center_w = (obj['xmax'] - obj['xmin']) / (float(self.config['IMAGE_W']) / self.config['GRID_W']) # unit: grid cell\n",
    "                        center_h = (obj['ymax'] - obj['ymin']) / (float(self.config['IMAGE_H']) / self.config['GRID_H']) # unit: grid cell\n",
    "\n",
    "                        box = [center_x, center_y, center_w, center_h]\n",
    "\n",
    "                        # find the anchor that best predicts this box\n",
    "                        best_anchor = -1\n",
    "                        max_iou     = -1\n",
    "\n",
    "                        shifted_box = BoundBox(0,\n",
    "                                               0,\n",
    "                                               center_w,\n",
    "                                               center_h)\n",
    "\n",
    "                        for i in range(len(self.anchors)):\n",
    "                            anchor = self.anchors[i]\n",
    "                            iou    = bbox_iou(shifted_box, anchor)\n",
    "\n",
    "                            if max_iou < iou:\n",
    "                                best_anchor = i\n",
    "                                max_iou     = iou\n",
    "\n",
    "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 0:4] = box\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 4  ] = 1.\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 5+obj_indx] = 1\n",
    "\n",
    "                        # assign the true box to b_batch\n",
    "                        b_batch[instance_count, 0, 0, 0, true_box_index] = box\n",
    "\n",
    "                        true_box_index += 1\n",
    "                        true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
    "\n",
    "            # assign input image to x_batch\n",
    "            if self.norm != None:\n",
    "                x_batch[instance_count] = self.norm(img)\n",
    "            else:\n",
    "                # plot image and bounding boxes for sanity check\n",
    "                for obj in all_objs:\n",
    "                    if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin']:\n",
    "                        cv2.rectangle(img[:,:,::-1], (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\n",
    "                        cv2.putText(img[:,:,::-1], obj['name'],\n",
    "                                    (obj['xmin']+2, obj['ymin']+12),\n",
    "                                    0, 1.2e-3 * img.shape[0],\n",
    "                                    (0,255,0), 2)\n",
    "\n",
    "                x_batch[instance_count] = img\n",
    "\n",
    "            # increase instance counter in current batch\n",
    "            instance_count += 1\n",
    "\n",
    "        #print(' new batch created', idx)\n",
    "\n",
    "        return [x_batch, b_batch], y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle: np.random.shuffle(self.images)\n",
    "\n",
    "    def aug_image(self, train_instance, jitter):\n",
    "        image_name = train_instance['filename']\n",
    "        image = cv2.imread(image_name)\n",
    "\n",
    "        if image is None: print('Cannot find ', image_name)\n",
    "\n",
    "        h, w, c = image.shape\n",
    "        all_objs = copy.deepcopy(train_instance['object'])\n",
    "\n",
    "        if jitter:\n",
    "            ### scale the image\n",
    "            scale = np.random.uniform() / 10. + 1.\n",
    "            image = cv2.resize(image, (0,0), fx = scale, fy = scale)\n",
    "\n",
    "            ### translate the image\n",
    "            max_offx = (scale-1.) * w\n",
    "            max_offy = (scale-1.) * h\n",
    "            offx = int(np.random.uniform() * max_offx)\n",
    "            offy = int(np.random.uniform() * max_offy)\n",
    "\n",
    "            image = image[offy : (offy + h), offx : (offx + w)]\n",
    "\n",
    "            ### flip the image\n",
    "            flip = np.random.binomial(1, .5)\n",
    "            if flip > 0.5: image = cv2.flip(image, 1)\n",
    "\n",
    "            image = self.aug_pipe.augment_image(image)\n",
    "\n",
    "        # resize the image to standard size\n",
    "        image = cv2.resize(image, (self.config['IMAGE_H'], self.config['IMAGE_W']))\n",
    "        image = image[:,:,::-1]\n",
    "\n",
    "        # fix object's position and size\n",
    "        for obj in all_objs:\n",
    "            for attr in ['xmin', 'xmax']:\n",
    "                if jitter: obj[attr] = int(obj[attr] * scale - offx)\n",
    "\n",
    "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_W']) / w)\n",
    "                obj[attr] = max(min(obj[attr], self.config['IMAGE_W']), 0)\n",
    "\n",
    "            for attr in ['ymin', 'ymax']:\n",
    "                if jitter: obj[attr] = int(obj[attr] * scale - offy)\n",
    "\n",
    "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_H']) / h)\n",
    "                obj[attr] = max(min(obj[attr], self.config['IMAGE_H']), 0)\n",
    "\n",
    "            if jitter and flip > 0.5:\n",
    "                xmin = obj['xmin']\n",
    "                obj['xmin'] = self.config['IMAGE_W'] - obj['xmax']\n",
    "                obj['xmax'] = self.config['IMAGE_W'] - xmin\n",
    "\n",
    "        return image, all_objs"
   ],
   "id": "b870aa7cb2d2863b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "538dc4cb0a6e4a30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f0234ecf66258e8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
